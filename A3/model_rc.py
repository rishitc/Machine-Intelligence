# -*- coding: utf-8 -*-
"""Model_rc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YgfdRudbwJNSO-3U0Nvw59toLAUA0DoQ

# The mode is in its best possible configuration
## Please don't change anything, before asking Rishit

## The test set accuracy is: 94.74%
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping

# from keras import backend as K

import numpy as np
import pandas as pd

import os

import seaborn as sns
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


df_train = pd.read_csv("train_split.csv")
df_valid = pd.read_csv("valid_split.csv")
df_test = pd.read_csv("test_split.csv")

# df.Education.replace(np.NaN, 5, inplace=True)
# df.Residence.fillna(df.Residence.mode()[0], inplace=True)
# df["Delivery phase"].fillna(df["Delivery phase"].mode()[0], inplace=True)
# df["Age"].fillna(df["Age"].median(axis=0), inplace=True)
# df["Weight"].fillna(df["Weight"].mean(axis=0), inplace=True)
# df["HB"].fillna(df["HB"].mean(axis=0), inplace=True)
# df["BP"].fillna(df["BP"].mean(axis=0), inplace=True)
# print(df)

# df.groupby('Result').count()

# def sampling_k_elements(group, k=24):
#     if len(group) < k:
#         return group
#     return group.sample(k)

# balanced1 = df.loc[df['Result'] == 0].groupby('Result').apply(sampling_k_elements, 24).reset_index(drop=True)
# balanced2 = df.loc[df['Result'] == 1].groupby('Result').apply(sampling_k_elements, 36).reset_index(drop=True)
# balanced = pd.concat([balanced2, balanced1])
# balanced.head()

# df = balanced
# balanced.shape # (rows, columns)

# data = []


# for i in range(len(df)):
#     data.append({
#             # "evidence": [int(df.iloc[i,0]), int(df.iloc[i,1]), int(df.iloc[i,2]), int(df.iloc[i,3]), float(df.iloc[i,4]), int(df.iloc[i,5]), float(df.iloc[i, 6]), int(df.iloc[i,7]), int(df.iloc[i, 8])],
#             "evidence": [int(df.iloc[i,0]), int(df.iloc[i,1]), float(df.iloc[i,2]), int(df.iloc[i,3]), float(df.iloc[i,4]), int(df.iloc[i,5]), float(df.iloc[i, 6]), int(df.iloc[i, 8])],
#             "label": int(df.iloc[i,9])
#         })

# ax1 = df.plot.scatter(x='Result',
#                       y='Delivery phase',  # 'Age' 'Community' 'Delivery phase' 'Weight' 'HB' 'IFA' 'BP'
#                       c='DarkBlue')

# df['Community'].unique()  # df['Delivery phase'].unique()

# df.loc[df['Delivery phase'] == 1].groupby('Result').count()

# df.loc[df['Delivery phase'] == 2].groupby('Result').count()

# df.loc[df['Community'] == 4].groupby('Result').count()

# data

# # Separate data into training and testing groups

# evidence = [row["evidence"] for row in data]
# labels = [row["label"] for row in data]
# X_training, X_testing, y_training, y_testing = train_test_split(
#     evidence, labels, test_size=0.25, random_state=42, stratify=labels
# )

# sum([1 for x in y_training if x == 1]), sum([1 for x in y_training if x == 0])

TARGET_COL_NAMES = ["Result_0.0", "Result_1.0"]

# Split features and target
X_train = df_train.drop(columns=TARGET_COL_NAMES)
X_valid = df_valid.drop(columns=TARGET_COL_NAMES)
y_train = df_train[TARGET_COL_NAMES]
y_valid = df_valid[TARGET_COL_NAMES]

X_test = df_test.drop(columns=TARGET_COL_NAMES)
y_test = df_test[TARGET_COL_NAMES]

COL_COUNT_INDEX = 1
NO_OF_TARGET_COLS = 2  # Just meta-data from devs

NO_OF_INPUT_COLS = X_train.shape[COL_COUNT_INDEX]

# All the below values were got using Adam optimizer

# Batch size = 48, dropout=0.1,
# 6, 3, 2 -> Minimum validation loss: 0.3162044286727905
# 8, 4, 2 -> Minimum validation loss: 0.3133411705493927
# 12, 6, 2 -> Minimum validation loss: 0.32757410407066345
# 8, 6, 2 -> Minimum validation loss: 0.31015336513519287

# Batch size = 52, dropout=0.1,
# 8, 6, 2 -> Minimum validation loss: 0.317778080701828
# 6, 3, 2 -> Minimum validation loss: 0.3258116543292999
# 12, 6, 2 -> Minimum validation loss: 0.33144840598106384

# Batch size = 48, no dropouts and only batchnormalization
# 8, 6, 2 -> Minimum validation loss: 0.2923494279384613

# Batch size = 48, Batchnormalization before first layer
# 8, 6, 2 -> Minimum validation loss: 0.29846498370170593

# Batch size = 48, Xavier and He, dropout=0.1, 
# 8, 6, 2 -> Best setup till now; Minimum validation loss: 0.28807809948921204

# Batch size = 48, Xavier and He, dropout_1_layer = 0.1, dropout_2_layer = 0.3
# 8, 6, 2 -> Minimum validation loss: 0.29950150847435

# Batch size = 48, Xavier and He, dropout_1_layer = 0.3, dropout_2_layer = 0.3
# 8, 6, 2 -> Minimum validation loss: 0.3288656771183014

# Batch size = 48, Xavier and He, dropout_1_layer = 0.2, dropout_2_layer = 0.2
# 8, 6, 2 -> Minimum validation loss: 0.319835901260376

# All the above usiing Xavier using GlorotNormal initialization
# GlorotUniform seems to be very much the same

# Create a neural network
model = keras.Sequential([

    # tf.keras.layers.Dense(10, input_shape=(9,)),
    # tf.keras.layers.LeakyReLU(alpha=0.1),
    # tf.keras.layers.Dropout(0.25),

    # tf.keras.layers.Dense(5, input_shape=(16,)),
    # tf.keras.layers.LeakyReLU(alpha=0.1),
    # tf.keras.layers.Dropout(0.25),

    # layers.BatchNormalization(input_shape=[NO_OF_INPUT_COLS]),

    # the hidden ReLU layers
    layers.Dense(units=8, name="hidden_layer_1", kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42), input_shape=[NO_OF_INPUT_COLS]),  # activation="relu",
    layers.Activation("relu"),
    layers.Dropout(rate=0.1),
    # layers.BatchNormalization(),
    layers.Dense(units=6, name="hidden_layer_2", kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42)),  # activation="relu",
    layers.Activation("relu"),
    layers.Dropout(rate=0.1),
    # layers.BatchNormalization(),
  
    # the softmax output layer 
    layers.Dense(units=2, name="output_layer", kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42)),  # activation="softmax",
    layers.Activation("softmax")
])

# Specifying the loss function and the optimizer function for the neural network
model.compile(
    optimizer= "adam",
    loss="binary_crossentropy",
    metrics=['binary_accuracy'],
)

early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=100, # how many epochs to wait before stopping, if no improvement greater than or equal to the threashold is found
    restore_best_weights=True,
)

history = model.fit(
                    X_train, y_train,
                    validation_data=(X_valid, y_valid),
                    batch_size=48,
                    epochs=10000,
                    callbacks=[early_stopping], # put your callbacks in a list
                )

# convert the training history to a dataframe
history_df = pd.DataFrame(history.history)
# use Pandas native plot method
history_df[['loss', 'val_loss']].plot()

print("Minimum training loss: {}".format(history_df['loss'].min()))

history_df['val_loss'].plot()

print("Minimum validation loss: {}".format(history_df['val_loss'].min()))

history_df.loc[1200:, ['loss', 'val_loss']].plot()

print(("Best Validation Loss: {:0.4f}" +\
      "\nBest Validation Accuracy: {:0.4f}")\
      .format(history_df['val_loss'].min(), 
              history_df['val_binary_accuracy'].max()))

loss_val, accuracy = model.evaluate(X_test, y_test)
print('Accuracy on test set: %.2f' % (accuracy*100))
print('Loss on test set: %.2f' % (loss_val * 100))

# # Define our custom loss function
# def focal_loss(y_true, y_pred):
#     gamma = 2
#     alpha = 0.1
#     pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))
#     pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))
#     return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))

# # Compile our model
# adam = tf.keras.optimizers.Adam(lr=0.1)
# model.compile(loss=[focal_loss], metrics=["accuracy"], optimizer=adam)

# opt = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
# # opt = tf.keras.optimizers.Adam(learning_rate=0.05)

# # Train neural network
# model.compile(
#     optimizer= opt,
#     loss="binary_crossentropy",
#     metrics=["accuracy"]
# )

# Evaluate how well model performs
# model.evaluate(X_testing, y_testing, verbose=2)

# ynew = model.predict_classes(X_testing)

# ynew

# y_testing

# tf.math.confusion_matrix(y_testing, ynew, 2)

a = tf.argmax(y_test, axis = 1)
b = tf.argmax(model.predict(X_test), axis=1)
tf.math.confusion_matrix(a, b, 2)

a

b

